"""Add the `annotate` command to the cyano-annotation CLI."""

import logging
from datetime import datetime
from pathlib import Path
from typing import Optional

import typer

from cyano_annotation.analysis import compare_gff
from cyano_annotation.converters import gbff_to_gff, merge_csv_to_gbff
from cyano_annotation.parsers import (
    build_egg_dictionary_clean,
    combine_gbk_files,
    egg_dict_to_tsv,
    ipr_dictotsv,
    ipr_termfinder,
    read_file_paths,
)
from cyano_annotation.visualization import gff_to_circos_png

from .main import LogLevel, app, setup_logger

logger = logging.getLogger("cyano_annotation")


@app.command(
    name="annotate",
    no_args_is_help=True,
    help="Run the genome annotation enhancement pipeline.",
)
def annotate(
    gbff_input: Path = typer.Option(
        ...,
        "--gbff-input",
        "-gbi",
        help="Input GBFF file generated by Bakta.",
        exists=True,
        file_okay=True,
        dir_okay=False,
        readable=True,
        resolve_path=True,
    ),
    output_file: Path = typer.Option(
        ...,
        "--output",
        "-o",
        help="Output GBFF file path.",
        file_okay=True,
        dir_okay=False,
        writable=True,
        resolve_path=True,
    ),
    egg_input: Optional[Path] = typer.Option(
        None,
        "--egg-input",
        "-ei",
        help="Input EggNOG annotation file (.tsv).",
        exists=True,
        file_okay=True,
        dir_okay=False,
        readable=True,
        resolve_path=True,
    ),
    ipr_input: Optional[Path] = typer.Option(
        None,
        "--ipr-input",
        "-ii",
        help="Input InterPro annotation file (.gff3).",
        exists=True,
        file_okay=True,
        dir_okay=False,
        readable=True,
        resolve_path=True,
    ),
    antismash_input: Optional[Path] = typer.Option(
        None,
        "--antismash-input",
        "-ai",
        help="Input antiSMASH annotation file (.json).",
        exists=True,
        file_okay=True,
        dir_okay=False,
        readable=True,
        resolve_path=True,
    ),
    pseudofinder_input: Optional[Path] = typer.Option(
        None,
        "--pseudofinder-input",
        "-pi",
        help="Input Pseudofinder annotation file (.gff).",
        exists=True,
        file_okay=True,
        dir_okay=False,
        readable=True,
        resolve_path=True,
    ),
    gecco_input: Optional[Path] = typer.Option(
        None,
        "--gecco-input",
        "-pi",
        help="Input Gecco csv file with all .gbk paths.",
        exists=True,
        file_okay=True,
        dir_okay=False,
        readable=True,
        resolve_path=True,
    ),
    gff_input: Optional[Path] = typer.Option(
        None,
        "--gff-input",
        "-gfi",
        help="Input GFF file for comparison.",
        exists=True,
        file_okay=True,
        dir_okay=False,
        readable=True,
        resolve_path=True,
    ),
    log_file: Optional[Path] = typer.Option(
        None,
        "--log-file",
        "-l",
        help="Optional log file path. If not provided, will be created in output directory.",
        file_okay=True,
        dir_okay=False,
    ),
    log_level: LogLevel = typer.Option(
        LogLevel.INFO,
        "--log-level",
        help="Set the desired log level.",
        case_sensitive=False,
    ),
    circos: bool = typer.Option(
        False,
        "--circos",
        help="Generate Circos visualization.",
    ),
    compare: bool = typer.Option(
        False,
        "--compare",
        help="Generate gff comparison file",
    ),
) -> None:
    """Run the cyanobacteria genome annotation enhancement pipeline."""
    # Prepare output directory and log file
    outdir = output_file.parent
    outdir.mkdir(parents=True, exist_ok=True)

    if log_file is None:
        log_file = outdir / f"pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

    setup_logger(log_file, log_level.value)
    logger.info("=== Starting Genome Annotation Pipeline ===")

    # Intermediate files
    egg_out = None
    ipr_out = None

    try:
        # Step 1: Process EggNOG
        if egg_input:
            logger.info("Processing EggNOG file...")
            EGG_Terms = build_egg_dictionary_clean(str(egg_input))
            egg_out = outdir / "eggnog_hits.tsv"
            egg_dict_to_tsv(EGG_Terms, str(egg_out))
            logger.info(f"EggNOG results written to {egg_out}")

        # Step 2: Process InterPro
        if ipr_input:
            logger.info("Processing InterPro file...")
            IPR_Terms = ipr_termfinder(str(ipr_input))
            ipr_out = outdir / "ipr_hits.tsv"
            ipr_dictotsv(IPR_Terms, str(ipr_out))
            logger.info(f"InterPro results written to {ipr_out}")

        # Step 3: Merge annotations into GBFF
        if egg_out or ipr_out:
            logger.info("Merging annotations into GBFF...")
            enhanced_gbff = merge_csv_to_gbff(
                egg_file=str(egg_out) if egg_out else None,
                interpro_file=str(ipr_out) if ipr_out else None,
                gbff_in=str(gbff_input),
                gbff_out=str(output_file),
                pseudofile=str(pseudofinder_input) if pseudofinder_input else None
            )
            logger.info(f"Merged GBFF written to {output_file}")
        else:
            logger.warning("No annotation files produced — skipping merge.")
            enhanced_gbff = str(gbff_input)

        if gecco_input:
            gecco_files = read_file_paths(gecco_input)

            if gecco_files:
                combined_gbk = Path(outdir) / "combined_gecco_clusters.gbk"
                combine_gbk_files(combined_gbk, gecco_files)
                gecco_clusters_gbk = str(combined_gbk)
            else:
                print("⚠️ No GECCO GBK files found in CSV. Skipping GECCO processing.")
                gecco_clusters_gbk = None
        else:
            gecco_clusters_gbk = None

        # Step 4: Convert GBFF to GFF
        gff_file = outdir / "Enhanced.gff"
        gff_generated = gbff_to_gff(enhanced_gbff, str(gff_file), str(antismash_input),str(gecco_clusters_gbk),antismash_version="7.1.0" )
        logger.info(f"Enhanced GFF file created: {gff_file}")

        # Step 5: Compare GFFs
        if compare:
            if gff_input and gff_input.exists() and gff_generated:
                csv_file = outdir / "gff_comparison.csv"
                compare_gff(str(gff_input), gff_generated, output_csv=str(csv_file))
                logger.info(f"GFF comparison completed → {csv_file}")

            elif not gff_generated:
                logger.warning("Enhanced GFF file not produced | No comparison initiated")

            else:
                logger.warning(f"Starting GFF file {gff_input} not found — skipping comparison.")

        # Step 6: (Optional) Generate circos plots
        if circos:

            if gff_generated:
                circos_png = outdir / "circos_enhanced.png"
                gff_to_circos_png(
                    gff_generated, str(circos_png)
                )
                logger.info(f"Circos plot created for enhanced GFF → {circos_png}")
            else:
                logger.warning("Skipping Circos step for enhanced GFF (not produced).")

            if gff_input and gff_input.exists():
                circos_png_input = outdir / "circos_input.png"
                gff_to_circos_png(
                    str(gff_input),
                    str(circos_png_input),
                )
                logger.info(f"Circos plot created for input GFF → {circos_png_input}")
            else:
                logger.warning(
                    f"Skipping Circos plot for missing input GFF {gff_input}"
                )

    except Exception as e:
        logger.exception(f"Pipeline failed with error: {e}")
        raise typer.Exit(code=1)

    logger.info("=== Pipeline completed successfully ===")
    logger.info(f"Full log saved at: {log_file}")

